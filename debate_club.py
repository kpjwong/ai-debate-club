import asyncio
import os
from agents import (
    Agent,
    Runner,
    function_tool,
    ItemHelpers,
    ModelSettings,
    # --- æ ¹æ®æ‚¨æä¾›çš„ dir(agents) è¾“å‡ºï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™äº›ç¡®åˆ‡å­˜åœ¨çš„ç±» ---
    ReasoningItem,
    ToolCallItem,
    ToolCallOutputItem,
    MessageOutputItem,
    set_default_openai_client
)
from openai import OpenAI, AsyncOpenAI

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
custom_openai_client = OpenAI(api_key=OPENAI_API_KEY)
custom_async_client = AsyncOpenAI(api_key=OPENAI_API_KEY)
set_default_openai_client(custom_async_client)

# --- æ­£æ–¹ Agent ---
ProAgent = Agent(
    name="ProAgent",
    model="gpt-5-mini-2025-08-07",
    instructions=(
        "You are a skilled debater arguing IN FAVOR of the motion. "
        "Provide clear, logical, and evidence-based arguments. "
        "When asked to rebut, directly address the points made by your opponent. "
        "Keep your responses concise and focused on the core argument."
    ),
    tools=[]
)

# --- åæ–¹ Agent ---
ConAgent = Agent(
    name="ConAgent",
    model="gpt-5-mini-2025-08-07",
    instructions=(
        "You are a skilled debater arguing AGAINST the motion. "
        "Provide clear, logical, and evidence-based arguments. "
        "When asked to rebut, directly address the points made by your opponent. "
        "Keep your responses concise and focused on the core argument."
    ),
    tools=[]
)

def create_tool_from_agent(agent: Agent, description: str):
    async def run_agent_as_tool(query: str) -> str:
        print("\n" + "="*20 + f" [ SWITCHING CONTEXT ] " + "="*20)
        print(f"Orchestrator is delegating task to sub-agent: {agent.name}")
        print(f"Sub-agent's task: '{query}'")
        print("="*65 + "\n")
        
        result = await Runner.run(agent, query, max_turns=1)
        output = ItemHelpers.text_message_outputs(result.new_items)
        
        print("\n" + "="*20 + f" [ RETURNING CONTEXT ] " + "="*20)
        print(f"Sub-agent {agent.name} has finished.")
        print(f"Returning result to Orchestrator.")
        print("="*65 + "\n")
        return output if output else "The agent did not provide a response."

    return function_tool(run_agent_as_tool, name_override=agent.name, description_override=description)

pro_agent_tool = create_tool_from_agent(
    agent=ProAgent,
    description="Use this to get the arguments FOR the motion (pro side)."
)
con_agent_tool = create_tool_from_agent(
    agent=ConAgent,
    description="Use this to get the arguments AGAINST the motion (con side)."
)
orchestrator_tools = [pro_agent_tool, con_agent_tool]
print("--- L1 Debater Agents wrapped as Tools for Orchestrator ---")

# --- Orchestrator Agent ---
OrchestratorAgent = Agent(
    name="DebateModerator",
    model="gpt-5-mini-2025-08-07",
    instructions=(
        "You are a STOIC and IMPARTIAL state machine-based debate moderator. "
        "Your SOLE function is to manage the debate flow by calling your tools according to a strict sequence of states. "
        "**YOU MUST NOT USE YOUR OWN KNOWLEDGE OR OPINIONS.**\n"
        "You operate in the following states. After each tool call, you will receive an observation. Based on the complete history, you must determine the current state and execute ONLY the action for the NEXT state.\n"
        "**STATES AND REQUIRED ACTIONS:**\n"
        "1. **START**: This is the initial state. Your action is to call `ProAgent`. The query MUST be: 'The debate motion is: [Insert Full Motion Here]. Please provide your opening statement.'\n"
        "2. **AWAITING_CON_OPENING**: You have the ProAgent's statement. Your action is to call `ConAgent`. The query MUST be: 'The debate motion is: [Insert Full Motion Here]. Please provide your opening statement.'\n"
        "3. **AWAITING_CON_REBUTTAL**: You have both opening statements. Your action is to call `ConAgent`. The query MUST be formatted EXACTLY like this: 'The debate motion is: [Insert Full Motion Here]. Here is the opponent's opening statement. Please provide a point-by-point rebuttal: [Insert ProAgent's full opening statement here]'.\n"
        "4. **AWAITING_PRO_REBUTTAL**: You have the Con's rebuttal. Your action is to call `ProAgent`. The query MUST be formatted EXACTLY like this: 'The debate motion is: [Insert Full Motion Here]. Here is the opponent's opening statement. Please provide a point-by-point rebuttal: [Insert ConAgent's full opening statement here]'.\n"
        "5. **AWAITING_PRO_SUMMARY**: You have both rebuttals. Your action is to call `ProAgent`. The query MUST include the motion AND the entire debate history for full context. For example: 'The debate motion was: [Insert Full Motion Here]. Based on the entire debate history below, provide your final summary: [Insert Full History Here]'.\n"
        "6. **AWAITING_CON_SUMMARY**: You have the Pro's summary. Your action is to call `ConAgent`. The query MUST also include the motion AND the entire debate history for full context.\n"
        "7. **REPORTING**: You have all summaries. This is the final state. Your action is to stop calling tools and output your final answer. Your final answer MUST be a compilation of the entire debate into a single, well-structured report. The report must contain clearly labeled sections for: 'Opening Statement (Pro)', 'Opening Statement (Con)', 'Rebuttal (Con)', 'Rebuttal (Pro)', 'Summary (Pro)', and 'Summary (Con)'. Summarize each round in ONE SENTENCE. "
    ),
    tools=orchestrator_tools,
    # --- å…³é”®ä¿®æ”¹ï¼šå¼ºåˆ¶æ¨¡å‹å¿…é¡»ä½¿ç”¨å·¥å…· ---
    # è¿™ä¼šè¿«ä½¿å®ƒåœ¨ç¬¬ä¸€æ­¥å°±æ€è€ƒâ€œæˆ‘è¯¥ç”¨å“ªä¸ªå·¥å…·ï¼Ÿâ€ï¼Œè€Œä¸æ˜¯â€œæˆ‘è¯¥å¦‚ä½•ç›´æ¥å›ç­”ï¼Ÿâ€
    model_settings=ModelSettings(tool_choice="required")
)
print("--- L2 Orchestrator Agent (DebateModerator) Created with ENFORCED instructions ---")

topic = "Anit-wokism is worse than wokism"
max_turns = 20

if asyncio.get_event_loop().is_running():
    # For Jupyter notebooks where event loop is already running
    result = await Runner.run(OrchestratorAgent, topic, max_turns=max_turns)
else:
    # For regular Python runtime
    result = asyncio.run(Runner.run(OrchestratorAgent, topic, max_turns=max_turns))

for item in result.new_items:
    # æˆ‘ä»¬ä¸å†æ£€æŸ¥ ReasoningItemï¼Œå› ä¸ºå®ƒä¸åŒ…å«å¯æ‰“å°çš„æ–‡æœ¬ã€‚
    # æˆ‘ä»¬ç›´æ¥å…³æ³¨å¯è§‚å¯Ÿçš„è¡ŒåŠ¨å’Œç»“æœã€‚

    # å½“æ¨¡å‹å†³å®šè°ƒç”¨å·¥å…·æ—¶
    if isinstance(item, ToolCallItem):
        # æ€è€ƒè¿‡ç¨‹å·²ç»éšå«åœ¨è¿™ä¸ªè¡ŒåŠ¨ä¸­äº†
        print(f"\nğŸ¤” [Thought -> Action] Agent '{OrchestratorAgent.name}' decided to call a tool.")
        
        # --- å…³é”®ä¿®å¤ï¼šä» raw_item ä¸­æå–ä¿¡æ¯ ---
        # æ ¹æ® OpenAI çš„æ ‡å‡† ToolCall ç»“æ„ï¼Œä¿¡æ¯åº”è¯¥åœ¨ raw_item.function ä¸­
        tool_name_to_print = "[Unknown Tool]"
        arguments_to_print = "[Unknown Arguments]"

        # raw_item å¯èƒ½æœ‰ä¸åŒçš„ç»“æ„ï¼Œæˆ‘ä»¬å®‰å…¨åœ°è®¿é—®å®ƒ
        if hasattr(item, 'raw_item') and item.raw_item:
            raw_tool_call = item.raw_item
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ 'function' å±æ€§ (æ ‡å‡† OpenAI æ ¼å¼)
            if hasattr(raw_tool_call, 'function') and raw_tool_call.function:
                function_call = raw_tool_call.function
                if hasattr(function_call, 'name'):
                    tool_name_to_print = function_call.name
                if hasattr(function_call, 'arguments'):
                    arguments_to_print = function_call.arguments
        
        print(f"   | Calling Tool: {tool_name_to_print}")
        
        # æˆªæ–­è¿‡é•¿çš„å‚æ•°
        args_str = str(arguments_to_print)
        if len(args_str) > 200:
            args_str = args_str[:200] + "..."
        print(f"   | With Arguments: {args_str}")

    # å½“å·¥å…·æ‰§è¡Œå®Œæ¯•ï¼Œç»“æœè¿”å›æ—¶
    elif isinstance(item, ToolCallOutputItem):
        print(f"\nğŸ‘€ [Observation] Result from a tool:")
        
        # å®‰å…¨åœ°è·å–å·¥å…·å
        tool_name_to_print = getattr(item, 'tool_name', "[Unknown Source Tool]")
        print(f"   | Source Tool: {tool_name_to_print}")
        
        output_text = getattr(item, 'output', "[No output property found]")
        for line in str(output_text).strip().split('\n'):
            print(f"   | {line}")

final_output = ItemHelpers.text_message_outputs(result.new_items)

if final_output:
    print(f"\nâœ… [Final Answer] Agent '{OrchestratorAgent.name}' has concluded:")
    for line in final_output.strip().split('\n'):
        print(f"   | {line}")
else:
    print(f"\nâš ï¸ [Warning] Agent '{OrchestratorAgent.name}' finished without a clear final text output.")